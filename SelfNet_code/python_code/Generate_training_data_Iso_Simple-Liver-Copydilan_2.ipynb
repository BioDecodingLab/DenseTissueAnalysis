{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b48be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Supporting_functions import *\n",
    "from WBNS import WBNS_image\n",
    "import RedLionfishDeconv as rl\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "from aicsimageio.readers import CziReader\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "import re\n",
    "\n",
    "from skimage import measure  \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61d3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "\n",
    "## Tiff source folders\n",
    "\n",
    "# Source paths for the tiff images if extractImagesFromCzi== True, the folders will be created\n",
    "srcpath = r'\\\\WS3\\WS3_Remote_Disk\\Current_Segovia_lab\\Deconvolution_Dilan\\data\\Synthetic_images_Jupyter\\Raw 3D/'\n",
    "dirSource = srcpath + 'Nuclei'\n",
    "dirTarget = srcpath + 'Nuclei'\n",
    "dirOut    = r'\\\\WS3\\WS3_Remote_Disk\\Current_Segovia_lab\\Deconvolution_Dilan\\data\\Deconvolution test\\SelfNet + RL\\Simulated_Jupyter/Nuclei/'\n",
    "psf_path = r'C:/SelfNet/PSF_confocal/PSF_far_red_647.tif'   #PSF_Red_568, PSF_Green_488, PSF_far_red_647\n",
    "\n",
    "\n",
    "resolution_scale = 0.2 # XY resolution / Z resolution, -1 if calculate from images\n",
    "\n",
    "## Generate image planes for training data \n",
    "## Process Target image\n",
    "processTargetImages = True\n",
    "# BG subtraction\n",
    "resolution_px = 0 # FWHM of the PSF: \n",
    "resolution_pz = 0\n",
    "noise_lvl = 2\n",
    "# deconvolution\n",
    "padding = 32\n",
    "Niter = 10\n",
    "# post processing\n",
    "sigmaLoG = 0.0\n",
    "sigmaLoGAddScale = 0.0\n",
    "sigma = 0.8\n",
    "# image normalization\n",
    "thres_scale_target = 2.0 # threhold for simple mask for normalization (original 2.0)\n",
    "percentiles_target = (30, 99.999)\n",
    "min_v_target = 0\n",
    "max_v_target = 65535\n",
    "# save processed images\n",
    "dirProcTarget = dirSource + '_deconvRL10/' \n",
    "\n",
    "## Process Source image\n",
    "# image normalization\n",
    "processSourceImages = True\n",
    "thres_scale_source = 1.5  # threhold for simple mask for normalization (1.5 original)\n",
    "percentiles_source = (30, 99.999)\n",
    "min_v_source = 0\n",
    "max_v_source = 65535\n",
    "\n",
    "\n",
    "\n",
    "## Parameters for the patch selection\n",
    "patch_size = 128\n",
    "stride = 128\n",
    "signal_intensity_threshold = 5000  #parameter for selecting image patches containing signals\n",
    "signal_fraction = 0.01    # min amount of pixel with intenity > signal_intensity_threshold\n",
    "Max_N_patches = 10000\n",
    "\n",
    "\n",
    "xy_interval=1\n",
    "xz_interval=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8f1bd",
   "metadata": {},
   "source": [
    "# Generate image planes for training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69713898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder: '\\\\WS3\\WS3_Remote_Disk\\Current_Segovia_lab\\Deconvolution_Dilan\\data\\Deconvolution test\\SelfNet + RL\\Simulated_Jupyter/Nuclei/' already exists\n"
     ]
    }
   ],
   "source": [
    "## Create folders to export data\n",
    "outDir = dirOut+\"raw_data/\"\n",
    "xy_data = outDir+\"xy/\"\n",
    "xy_lr_data = outDir+\"xy_lr/\"\n",
    "xz_data = outDir+\"xz/\"\n",
    "   \n",
    "createFolder(dirOut)\n",
    "createFolder(outDir)\n",
    "createFolder(xy_data)\n",
    "createFolder(xy_lr_data)\n",
    "createFolder(xz_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967610ca",
   "metadata": {},
   "source": [
    "## Generate image planes for target and intermediate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c21cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Processing image : Nuclei_GT_Ch2_Mask_15_SNR.tif\n",
      "     -image dimension from : (272, 884, 1696) to (272, 884, 1696)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  102.0\n",
      "     -threshold_value: 204.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Failed to setup Reikna with OpenCL.\n",
      "ERROR:root:No module named 'mako'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     -size(GB) :  2.0884323120117188\n",
      "Intensity Norm  from (0 , 76) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [06:10, 370.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 370.3049 seconds, image Nuclei_GT_Ch2_Mask_15_SNR.tif, 272 images exported \n",
      "** Processing image : Nuclei_GT_Ch2_Mask_1_SNR.tif\n",
      "     -image dimension from : (272, 884, 1696) to (272, 884, 1696)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  120.0\n",
      "     -threshold_value: 240.0\n",
      "     -size(GB) :  2.0884323120117188\n",
      "Intensity Norm  from (0 , 23) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [12:17, 368.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 366.9221 seconds, image Nuclei_GT_Ch2_Mask_1_SNR.tif, 544 images exported \n",
      "** Processing image : Nuclei_GT_Ch2_Mask_5_SNR.tif\n",
      "     -image dimension from : (272, 884, 1696) to (272, 884, 1696)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  107.0\n",
      "     -threshold_value: 214.0\n",
      "     -size(GB) :  2.0884323120117188\n",
      "Intensity Norm  from (0 , 60) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [18:12, 362.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 355.3537 seconds, image Nuclei_GT_Ch2_Mask_5_SNR.tif, 816 images exported \n",
      "** Processing image : Nuclei_GT_Ch3_Mask_15_SNR.tif\n",
      "     -image dimension from : (275, 890, 1712) to (275, 890, 1712)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  101.0\n",
      "     -threshold_value: 202.0\n",
      "     -size(GB) :  2.139691472053528\n",
      "Intensity Norm  from (0 , 81) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [26:06, 406.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 473.8027 seconds, image Nuclei_GT_Ch3_Mask_15_SNR.tif, 1091 images exported \n",
      "** Processing image : Nuclei_GT_Ch3_Mask_1_SNR.tif\n",
      "     -image dimension from : (275, 890, 1712) to (275, 890, 1712)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  128.0\n",
      "     -threshold_value: 256.0\n",
      "     -size(GB) :  2.139691472053528\n",
      "Intensity Norm  from (0 , 23) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [33:51, 427.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 464.7746 seconds, image Nuclei_GT_Ch3_Mask_1_SNR.tif, 1366 images exported \n",
      "** Processing image : Nuclei_GT_Ch3_Mask_5_SNR.tif\n",
      "     -image dimension from : (275, 890, 1712) to (275, 890, 1712)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  109.0\n",
      "     -threshold_value: 218.0\n",
      "     -size(GB) :  2.139691472053528\n",
      "Intensity Norm  from (0 , 66) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [42:04, 449.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 493.2997 seconds, image Nuclei_GT_Ch3_Mask_5_SNR.tif, 1641 images exported \n",
      "** Processing image : Nuclei_GT_G1_Mask_15_SNR.tif\n",
      "     -image dimension from : (259, 868, 1660) to (259, 868, 1660)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  100.0\n",
      "     -threshold_value: 200.0\n",
      "     -size(GB) :  1.933373749256134\n",
      "Intensity Norm  from (0 , 75) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [51:17, 483.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 552.9311 seconds, image Nuclei_GT_G1_Mask_15_SNR.tif, 1900 images exported \n",
      "** Processing image : Nuclei_GT_G1_Mask_1_SNR.tif\n",
      "     -image dimension from : (259, 868, 1660) to (259, 868, 1660)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  152.0\n",
      "     -threshold_value: 304.0\n",
      "     -size(GB) :  1.933373749256134\n",
      "Intensity Norm  from (0 , 24) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [1:00:29, 505.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 552.1072 seconds, image Nuclei_GT_G1_Mask_1_SNR.tif, 2159 images exported \n",
      "** Processing image : Nuclei_GT_G1_Mask_5_SNR.tif\n",
      "     -image dimension from : (259, 868, 1660) to (259, 868, 1660)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  103.0\n",
      "     -threshold_value: 206.0\n",
      "     -size(GB) :  1.933373749256134\n",
      "Intensity Norm  from (0 , 58) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [1:09:41, 520.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 552.4752 seconds, image Nuclei_GT_G1_Mask_5_SNR.tif, 2418 images exported \n",
      "** Processing image : Nuclei_GT_G2_Mask_15_SNR.tif\n",
      "     -image dimension from : (280, 864, 1654) to (280, 864, 1654)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  101.0\n",
      "     -threshold_value: 202.0\n",
      "     -size(GB) :  2.043100357055664\n",
      "Intensity Norm  from (0 , 65) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [1:18:21, 519.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 519.1355 seconds, image Nuclei_GT_G2_Mask_15_SNR.tif, 2698 images exported \n",
      "** Processing image : Nuclei_GT_G2_Mask_1_SNR.tif\n",
      "     -image dimension from : (280, 864, 1654) to (280, 864, 1654)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  128.0\n",
      "     -threshold_value: 256.0\n",
      "     -size(GB) :  2.043100357055664\n",
      "Intensity Norm  from (0 , 26) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [1:26:50, 516.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 509.1059 seconds, image Nuclei_GT_G2_Mask_1_SNR.tif, 2978 images exported \n",
      "** Processing image : Nuclei_GT_G2_Mask_5_SNR.tif\n",
      "     -image dimension from : (280, 864, 1654) to (280, 864, 1654)\n",
      "     -z-space from : 1.0 to 1.0\n",
      "mode_result.mode :  105.0\n",
      "     -threshold_value: 210.0\n",
      "     -size(GB) :  2.043100357055664\n",
      "Intensity Norm  from (0 , 55) to  (0, 65534)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [1:35:21, 476.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 511.0420 seconds, image Nuclei_GT_G2_Mask_5_SNR.tif, 3258 images exported \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all tif images in the target folder, process and export them\n",
    "image_names = sorted([f for f in os.listdir(dirTarget) if f.endswith('.tif')])\n",
    "\n",
    "if processTargetImages == True:\n",
    "    #Creat output folder\n",
    "    createFolder(dirProcTarget)\n",
    "    # Open PSF and Prepare PSF\n",
    "    psf = tifffile.imread(psf_path)\n",
    "    psf_f = psf.astype(np.float32)\n",
    "    psf_norm = psf_f/psf_f.sum()\n",
    "\n",
    "    \n",
    "count = 1\n",
    "for i, image_name in tqdm(enumerate(image_names)):\n",
    "\n",
    "    start_time = time.time()  # Record the start time \n",
    "    print(f\"** Processing image : {image_name}\")\n",
    "    \n",
    "    # Open image and get metadata\n",
    "    img_path = os.path.join(dirTarget, image_name)   \n",
    "    img = tifffile.imread(img_path)\n",
    "    img_shape = img.shape\n",
    "    [physical_pixel_sizeX,physical_pixel_sizeY,physical_pixel_sizeZ] = read_tiff_voxel_size(img_path)    \n",
    "    scale = physical_pixel_sizeX / physical_pixel_sizeZ\n",
    "    \n",
    "\n",
    "    \n",
    "    if processTargetImages == True:\n",
    "        # Make image isotropic\n",
    "        if abs(1.0-scale) > 1e-4: \n",
    "            img = reslice(img,'xy',physical_pixel_sizeX,physical_pixel_sizeZ)\n",
    "        img = img.astype(np.float32)\n",
    "        new_img_shape = img.shape   \n",
    "        new_physical_pixel_sizeZ = img_shape[0] * physical_pixel_sizeZ / new_img_shape[0]\n",
    "        print(f\"     -image dimension from : {img_shape} to {new_img_shape}\")\n",
    "        print(f\"     -z-space from : {physical_pixel_sizeZ} to {new_physical_pixel_sizeZ}\")\n",
    "\n",
    "        # Get mask\n",
    "        mask = get_image_simple_mask(img, 0.0, 1.0, thres_scale_target)  \n",
    "        mask =  mask.astype(np.int16)\n",
    "    \n",
    "        # Deconvolution\n",
    "        if Niter > 0: \n",
    "            # Padding image\n",
    "            img = np.pad(img, padding, mode='reflect')\n",
    "            imgSizeGB = img.nbytes / (1024 ** 3)\n",
    "            print('     -size(GB) : ', imgSizeGB)\n",
    "            # GPU deconvolution\n",
    "            res_gpu = rl.doRLDeconvolutionFromNpArrays(img, psf, niter=Niter,resAsUint8=False)\n",
    "            # Removing padding\n",
    "            img = res_gpu[padding:-padding, padding:-padding, padding:-padding]\n",
    "\n",
    "        # Remove noise and BG\n",
    "        if resolution_px > 0:\n",
    "            img = WBNS_image(img, resolution_px, noise_lvl)\n",
    "            if resolution_pz > 0:\n",
    "                img_xz=np.transpose(img,[1,0,2])\n",
    "                img_xz = WBNS_image(img_xz, resolution_pz, 0)\n",
    "                img = np.transpose(img_xz,[1,0,2])\n",
    "        # LoG filter\n",
    "        if sigmaLoG > 0 :\n",
    "            imgBorders = ndi.gaussian_laplace(img, sigmaLoG)\n",
    "            imgBorders *= -1.0\n",
    "            #imgBorders[imgBorders < 0] = 0\n",
    "            imgBorders *= sigmaLoGAddScale\n",
    "            img += imgBorders\n",
    "        \n",
    "        # Smooth\n",
    "        if sigma > 0:\n",
    "\n",
    "            \n",
    "        \n",
    "        # Image Normalization\n",
    "        if percentiles_target[0] > 0 or percentiles_target[1] < 100:\n",
    "            low_thres, high_thres0 = getNormalizationThresholds(img, percentiles_target) # low thres in whole image\n",
    "            low_thres0, high_thres = getNormalizationThresholds(img * mask, percentiles_target) # high thres in FG\n",
    "            img = remove_outliers_image(img, low_thres, high_thres)\n",
    "\n",
    "        img = image_scaling(img, min_v_target, max_v_target, True)\n",
    "        img = img.astype(np.uint16)\n",
    "        \n",
    "        # Save processed image\n",
    "        img_out_name = os.path.join(dirProcTarget, image_name)            \n",
    "        tifffile.imwrite(      \n",
    "            img_out_name,\n",
    "            img,\n",
    "            imagej=True, \n",
    "            resolution=(1.0/physical_pixel_sizeX, 1.0/physical_pixel_sizeY), \n",
    "            metadata={'spacing': new_physical_pixel_sizeZ, 'unit': 'um', 'axes': 'ZYX'})\n",
    "        \n",
    "    # Generate intermediate images down sample and then upsample\n",
    "    if resolution_scale < 0:\n",
    "        resolution_scale = scale\n",
    "        \n",
    "    img_lr = np.zeros_like(img)\n",
    "    z,y,x = img.shape    \n",
    "    new_y = round(y * resolution_scale)\n",
    "    new_x = round(x * resolution_scale)\n",
    "    \n",
    "    for i in range(z):\n",
    "        temp_img  = cv2.resize(img[i,:,:],(new_x,new_y),interpolation=cv2.INTER_CUBIC)\n",
    "        #img_lr[i,:,:] = cv2.resize(temp_img,(x,y),interpolation=cv2.INTER_CUBIC)  \n",
    "        img_lr[i,:,:] = cv2.resize(temp_img,(x,y),interpolation=cv2.INTER_LINEAR) \n",
    "            \n",
    "    # Export planes for target and intermediate images, each plane as a TIFF image \n",
    "    \n",
    "    for i in range(z):\n",
    "        outName_target = f\"{xy_data}{count}.tif\"\n",
    "        outName_interm = f\"{xy_lr_data}{count}.tif\"\n",
    "        tifffile.imwrite(outName_target, img[i,:,:])\n",
    "        tifffile.imwrite(outName_interm, img_lr[i,:,:])      \n",
    "        count += 1\n",
    "  \n",
    "    Elapsed_time = time.time() - start_time\n",
    "    print(f\"Elapsed Time: {Elapsed_time:.4f} seconds, image {image_name}, {count-1} images exported \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6413242-63fd-4220-ba70-4baba3f92366",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a048bbdd",
   "metadata": {},
   "source": [
    "## Generate image planes for source images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8efc585b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Processing image : Nuclei_GT_Ch2_Mask_15_SNR.tif\n",
      "mode_result.mode :  102\n",
      "     -threshold_value: 153.0\n",
      "Intensity Norm  from (0 , 1242) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:29, 89.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 89.9922 seconds, image Nuclei_GT_Ch2_Mask_15_SNR.tif, 2580 images exported \n",
      "** Processing image : Nuclei_GT_Ch2_Mask_1_SNR.tif\n",
      "mode_result.mode :  120\n",
      "     -threshold_value: 180.0\n",
      "Intensity Norm  from (0 , 3947) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [02:58, 89.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 88.9508 seconds, image Nuclei_GT_Ch2_Mask_1_SNR.tif, 5160 images exported \n",
      "** Processing image : Nuclei_GT_Ch2_Mask_5_SNR.tif\n",
      "mode_result.mode :  107\n",
      "     -threshold_value: 160.5\n",
      "Intensity Norm  from (0 , 1435) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [04:30, 90.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 91.1566 seconds, image Nuclei_GT_Ch2_Mask_5_SNR.tif, 7740 images exported \n",
      "** Processing image : Nuclei_GT_Ch3_Mask_15_SNR.tif\n",
      "mode_result.mode :  101\n",
      "     -threshold_value: 151.5\n",
      "Intensity Norm  from (0 , 1294) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [06:04, 91.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 94.4597 seconds, image Nuclei_GT_Ch3_Mask_15_SNR.tif, 10342 images exported \n",
      "** Processing image : Nuclei_GT_Ch3_Mask_1_SNR.tif\n",
      "mode_result.mode :  128\n",
      "     -threshold_value: 192.0\n",
      "Intensity Norm  from (0 , 3975) to  (0, 65534)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [07:35, 91.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 91.2179 seconds, image Nuclei_GT_Ch3_Mask_1_SNR.tif, 12944 images exported \n",
      "** Processing image : Nuclei_GT_Ch3_Mask_5_SNR.tif\n",
      "mode_result.mode :  109\n",
      "     -threshold_value: 163.5\n",
      "Intensity Norm  from (0 , 1461) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [09:10, 92.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 95.0034 seconds, image Nuclei_GT_Ch3_Mask_5_SNR.tif, 15546 images exported \n",
      "** Processing image : Nuclei_GT_G1_Mask_15_SNR.tif\n",
      "mode_result.mode :  100\n",
      "     -threshold_value: 150.0\n",
      "Intensity Norm  from (0 , 1268) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [10:38, 90.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 87.2899 seconds, image Nuclei_GT_G1_Mask_15_SNR.tif, 18074 images exported \n",
      "** Processing image : Nuclei_GT_G1_Mask_1_SNR.tif\n",
      "mode_result.mode :  152\n",
      "     -threshold_value: 228.0\n",
      "Intensity Norm  from (0 , 4047) to  (0, 65534)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [12:04, 89.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 86.6803 seconds, image Nuclei_GT_G1_Mask_1_SNR.tif, 20602 images exported \n",
      "** Processing image : Nuclei_GT_G1_Mask_5_SNR.tif\n",
      "mode_result.mode :  103\n",
      "     -threshold_value: 154.5\n",
      "Intensity Norm  from (0 , 1457) to  (0, 65534)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [13:33, 89.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 88.8220 seconds, image Nuclei_GT_G1_Mask_5_SNR.tif, 23130 images exported \n",
      "** Processing image : Nuclei_GT_G2_Mask_15_SNR.tif\n",
      "mode_result.mode :  101\n",
      "     -threshold_value: 151.5\n",
      "Intensity Norm  from (0 , 1302) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [15:08, 90.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 94.5750 seconds, image Nuclei_GT_G2_Mask_15_SNR.tif, 25648 images exported \n",
      "** Processing image : Nuclei_GT_G2_Mask_1_SNR.tif\n",
      "mode_result.mode :  128\n",
      "     -threshold_value: 192.0\n",
      "Intensity Norm  from (0 , 3915) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [16:41, 91.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 93.1811 seconds, image Nuclei_GT_G2_Mask_1_SNR.tif, 28166 images exported \n",
      "** Processing image : Nuclei_GT_G2_Mask_5_SNR.tif\n",
      "mode_result.mode :  105\n",
      "     -threshold_value: 157.5\n",
      "Intensity Norm  from (0 , 1469) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [18:14, 91.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 93.1423 seconds, image Nuclei_GT_G2_Mask_5_SNR.tif, 30684 images exported \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all tif images in the dirSource folder, process and export them\n",
    "image_names = sorted([f for f in os.listdir(dirSource) if f.endswith('.tif')])\n",
    "\n",
    "count = 1\n",
    "for i, image_name in tqdm(enumerate(image_names)):\n",
    "\n",
    "    start_time = time.time()  # Record the start time \n",
    "    print(f\"** Processing image : {image_name}\")\n",
    "    \n",
    "    # Open image and get metadata\n",
    "    img_path = os.path.join(dirSource, image_name)   \n",
    "    img = tifffile.imread(img_path)\n",
    "    img_shape = img.shape\n",
    "    [physical_pixel_sizeX,physical_pixel_sizeY,physical_pixel_sizeZ] = read_tiff_voxel_size(img_path)    \n",
    "    scale = physical_pixel_sizeX / physical_pixel_sizeZ\n",
    " \n",
    "\n",
    "    if processSourceImages: \n",
    "        # Get mask\n",
    "        mask = get_image_simple_mask(img, 0.0, 1.0, thres_scale_source)  \n",
    "        mask =  mask.astype(np.int16)\n",
    "        # Image Normalization\n",
    "        if percentiles_source[0] > 0 or percentiles_source[1] < 100:\n",
    "            low_thres, high_thres0 = getNormalizationThresholds(img, percentiles_source) # low thres in whole image\n",
    "            low_thres0, high_thres = getNormalizationThresholds(img * mask, percentiles_source) # high thres in FG\n",
    "            img = remove_outliers_image(img, low_thres, high_thres)\n",
    "\n",
    "        img = image_scaling(img, min_v_source, max_v_source, True)\n",
    "        img = img.astype(np.uint16)\n",
    "\n",
    "    # reslice Image\n",
    "    img_xz = reslice(img,'xz',physical_pixel_sizeX,physical_pixel_sizeZ)\n",
    "    \n",
    "    z,y,x = img_xz.shape \n",
    "    \n",
    "    for i in range(z):\n",
    "        outName_target = f\"{xz_data}{count}.tif\"\n",
    "        tifffile.imwrite(outName_target, img_xz[i,:,:])\n",
    "        count += 1\n",
    "  \n",
    "    # reslice Image\n",
    "    img_yz = reslice(img,'yz',physical_pixel_sizeX,physical_pixel_sizeZ)\n",
    "    \n",
    "    z,y,x = img_yz.shape \n",
    "    \n",
    "    for i in range(z):\n",
    "        outName_target = f\"{xz_data}{count}.tif\"\n",
    "        tifffile.imwrite(outName_target, img_yz[i,:,:])\n",
    "        count += 1\n",
    "\n",
    "    Elapsed_time = time.time() - start_time\n",
    "    print(f\"Elapsed Time: {Elapsed_time:.4f} seconds, image {image_name}, {count-1} images exported \")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc30eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01dc63a6",
   "metadata": {},
   "source": [
    "# Generate training data from image planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c25ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder output \n",
    "train_data_path = os.path.join(dirOut, 'train_data/')\n",
    "createFolder(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c095ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3258/3258 [03:40<00:00, 14.77it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 7671/7671 [01:31<00:00, 83.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " From xy: 236512, xy_lr: 236512, xz: 126274 to xy: 10000, xy_lr: 10000, xz: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_fraction_over_threshold(crop_xy: np.ndarray, signal_intensity_threshold: float) -> float:\n",
    "    total_elements = crop_xy.size  # Total number of elements in the array\n",
    "    elements_above_threshold = np.sum(crop_xy > signal_intensity_threshold)  # Count elements greater than threshold\n",
    "    percentage = (elements_above_threshold / total_elements) \n",
    "\n",
    "    return percentage\n",
    "\n",
    "# Initialize arrays\n",
    "\n",
    "xy = []\n",
    "xy_lr = []\n",
    "xz = []\n",
    "\n",
    "# Loop over lateral images\n",
    "file_list_xy = os.listdir(xy_data)\n",
    "for i in tqdm(range(0, len(file_list_xy), xy_interval)):\n",
    "    xy_img = tifffile.imread(xy_data + str(i + 1) + '.tif')\n",
    "    xy_lr_img = tifffile.imread(xy_lr_data + str(i + 1) + '.tif')\n",
    "    L0 = min(xy_img.shape[0], xy_lr_img.shape[0])\n",
    "    L1 = min(xy_img.shape[1], xy_lr_img.shape[1])\n",
    "    for m in range(0, L0 - patch_size + 1, stride):\n",
    "        for n in range(0, L1 - patch_size + 1, stride):\n",
    "            crop_xy    =    xy_img[m:m + patch_size, n:n + patch_size]\n",
    "            crop_xy_lr = xy_lr_img[m:m + patch_size, n:n + patch_size]\n",
    "            \n",
    "            signal_f = calculate_fraction_over_threshold(crop_xy, signal_intensity_threshold)            \n",
    "            if signal_f > signal_fraction:\n",
    "                xy.append(crop_xy)\n",
    "                xy_lr.append(crop_xy_lr)\n",
    "\n",
    "# Loop over axial images   \n",
    "file_list_xz = os.listdir(xz_data)\n",
    "for i in tqdm(range(0, len(file_list_xz), xz_interval)):\n",
    "    xz_img = tifffile.imread(xz_data + str(i + 1) + '.tif')\n",
    "    for m in range(0, xz_img.shape[0] - patch_size + 1, stride):\n",
    "        for n in range(0, xz_img.shape[1] - patch_size + 1, stride):\n",
    "            crop_xz = xz_img[m:m + patch_size, n:n + patch_size]\n",
    "            signal_f = calculate_fraction_over_threshold(crop_xz, signal_intensity_threshold)\n",
    "            if signal_f > signal_fraction:\n",
    "                xz.append(crop_xz)# Chose randomly the patches\n",
    "minPatches = np.amin([len(xy),len(xz) ])\n",
    "\n",
    "if Max_N_patches > minPatches:\n",
    "    Max_N_patches = minPatches \n",
    "    \n",
    "# Random index for xy\n",
    "random_selection_indices = random.sample(range(len(xy)), Max_N_patches)  # Get the random indices\n",
    "\n",
    "# Use the same indices to select elements from both lists\n",
    "xy_new = [xy[i] for i in random_selection_indices]\n",
    "xy_lr_new = [xy_lr[i] for i in random_selection_indices]\n",
    "\n",
    "# Random elemnts form xz\n",
    "\n",
    "xz_new = random.sample(xz, Max_N_patches)\n",
    "\n",
    "print(f\" From xy: {len(xy)}, xy_lr: {len(xy_lr)}, xz: {len(xz)} to xy: {len(xy_new)}, xy_lr: {len(xy_lr_new)}, xz: {len(xz_new)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b1347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " From xy: 236512, xy_lr: 236512, xz: 126274 to xy: 10000, xy_lr: 10000, xz: 10000\n"
     ]
    }
   ],
   "source": [
    "# Chose randomly the patches\n",
    "minPatches = np.amin([len(xy),len(xz) ])\n",
    "\n",
    "if Max_N_patches > minPatches:\n",
    "    Max_N_patches = minPatches \n",
    "    \n",
    "# Random index for xy\n",
    "random_selection_indices = random.sample(range(len(xy)), Max_N_patches)  # Get the random indices\n",
    "\n",
    "# Use the same indices to select elements from both lists\n",
    "xy_new = [xy[i] for i in random_selection_indices]\n",
    "xy_lr_new = [xy_lr[i] for i in random_selection_indices]\n",
    "\n",
    "# Random elemnts form xz\n",
    "\n",
    "xz_new = random.sample(xz, Max_N_patches)\n",
    "\n",
    "print(f\" From xy: {len(xy)}, xy_lr: {len(xy_lr)}, xz: {len(xz)} to xy: {len(xy_new)}, xy_lr: {len(xy_lr_new)}, xz: {len(xz_new)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad39f7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128, 128) (10000, 128, 128) (10000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# Convert to arays and save\n",
    "\n",
    "xy = np.array(xy_new, dtype=np.float32)\n",
    "xy_lr = np.array(xy_lr_new, dtype=np.float32)\n",
    "xz = np.array(xz_new, dtype=np.float32)\n",
    "print(xy.shape, xy_lr.shape, xz.shape)\n",
    "\n",
    "np.savez(os.path.join(train_data_path, 'train_data.npz'), xy=xy, xy_lr=xy_lr, xz=xz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd22c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save tiff to double check\n",
    "\n",
    "import tifffile as tiff\n",
    "tiff.imwrite(os.path.join(train_data_path,'xy.tif'), xy)\n",
    "tiff.imwrite(os.path.join(train_data_path,'xy_lr.tif'), xy_lr)\n",
    "tiff.imwrite(os.path.join(train_data_path,'xz.tif'), xz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501428f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
