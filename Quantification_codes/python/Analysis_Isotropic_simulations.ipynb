{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VcS4Y4gqBRAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WG85hpmEx5A",
        "outputId": "0c3407c3-c8ee-4c22-ff20-3da5ef158db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsVsDf_Ntfhd",
        "outputId": "a6007e0b-c3b0-45ac-aaf0-2be5424e0087"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(np.float64(0.9129659137064984), (np.float64(-1.7745507592982686), np.float64(0.9129659137064984), np.float64(3.0)), (np.float64(-13.934775105273449), np.float64(0.0004000803625620637), np.float64(3.0)))\n",
            "3\n",
            "(np.float64(0.979146461437787), (np.float64(14.56595050257073), np.float64(0.0003508358188776554), np.float64(3.0)), (np.float64(3.4244447576975037), np.float64(0.979146461437787), np.float64(3.0)))\n",
            "3\n",
            "(np.float64(0.9823345102500135), (np.float64(11.511119630322064), np.float64(0.0007037412248025605), np.float64(3.0)), (np.float64(3.656516173218515), np.float64(0.9823345102500135), np.float64(3.0)))\n",
            "3\n",
            "(np.float64(0.001998223586037984), (np.float64(8.055086320937342), np.float64(0.001998223586037984), np.float64(3.0)), (np.float64(-15.157289798479741), np.float64(0.00031175425198779686), np.float64(3.0)))\n",
            "3\n",
            "(np.float64(0.0012199278254164875), (np.float64(9.635664369306616), np.float64(0.0011863360848038496), np.float64(3.0)), (np.float64(-9.544090046864099), np.float64(0.0012199278254164875), np.float64(3.0)))\n",
            "3\n",
            "(np.float64(0.0001958175679461356), (np.float64(25.272781873288597), np.float64(6.79264909918293e-05), np.float64(3.0)), (np.float64(-17.723303569317466), np.float64(0.0001958175679461356), np.float64(3.0)))\n",
            "3\n",
            "(np.float64(6.4349450554066805e-06), (np.float64(55.521729652280335), np.float64(6.4349450554066805e-06), np.float64(3.0)), (np.float64(-66.98291338533933), np.float64(3.666066144612356e-06), np.float64(3.0)))\n",
            "3\n",
            "(np.float64(0.0006341081323488715), (np.float64(48.004083811537534), np.float64(9.952407291479467e-06), np.float64(3.0)), (np.float64(-11.925146801351552), np.float64(0.0006341081323488715), np.float64(3.0)))\n",
            "3\n",
            "\n",
            "=== Ranking (closest to target) — vs Raw ===\n",
            "simulation  abs_mean_diff  mean_diff  boot95_mean_lo  boot95_mean_hi  p_wilcoxon_holm   tost_p\n",
            "    GANSim       0.152983  -0.152983       -0.227225       -0.084494              0.5 0.001998\n",
            " CSim_SNR1       0.645931  -0.645931       -0.780606       -0.511256              0.5 0.912966\n",
            " CSim_SNR5       0.807359   0.807359        0.644404        0.937055              0.5 0.979146\n",
            "CSim_SNR15       0.965525   0.965525        0.739170        1.147843              0.5 0.982335\n",
            "\n",
            "=== Ranking (closest to target) — vs ideal 1 ===\n",
            "      simulation  abs_mean_diff  mean_diff  boot95_mean_lo  boot95_mean_hi  p_wilcoxon_holm   tost_p\n",
            "CSimIsoRef_SNR15       0.046779  -0.046779       -0.060099       -0.034288              0.5 0.000006\n",
            " CSimIsoRef_SNR1       0.080214   0.002387       -0.081427        0.082601              1.0 0.001220\n",
            " CSimIsoRef_SNR5       0.087793   0.087793        0.047982        0.122768              0.5 0.000196\n",
            "      GAN_IsoRef       0.301013   0.301013        0.267527        0.320616              0.5 0.000634\n",
            "\n",
            "Saved figures:\n",
            "  Sinusoids_RAW_A_slope.eps/.png\n",
            "  Sinusoids_RAW_B_diff.eps/.png\n",
            "  Sinusoids_ISO_A_slope.eps/.png\n",
            "  Sinusoids_ISO_B_diff.eps/.png\n",
            "\n",
            "Saved tables:\n",
            "  Sinusoids_summary_vs_raw.csv\n",
            "  Sinusoids_summary_vs_iso.csv\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Paired slope plot + difference plot + effect sizes + bootstrap CI\n",
        "+ corrected paired tests + Equivalence testing (TOST)\n",
        "\n",
        "High-quality, journal-ready figures (svg + 600 dpi PNG).\n",
        "\n",
        "Dependencies:\n",
        "  pip install numpy pandas scipy statsmodels matplotlib\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import wilcoxon\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from statsmodels.stats.weightstats import ttost_paired\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# -----------------------------\n",
        "# 1) SETTINGS\n",
        "# -----------------------------\n",
        "element = \"Sinusoids\" # or \"BC\", \"Nuclei\", \"Sinusoids\", \"Membranes\"\n",
        "OUT_PREFIX = element\n",
        "OUT_DIR = Path(\"/content/drive/MyDrive/Manuscripts/LivesIsotropicReconstruction/data/results/figure2c/\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Equivalence bounds (choose a scientifically meaningful tolerance!)\n",
        "# Example: within ±0.20 of the target is considered \"equivalent\"\n",
        "EQ_BOUNDS_RAW = (-0.50, 0.50)   # for (Sim - Raw)\n",
        "EQ_BOUNDS_ISO = (-0.50, 0.50)   # for (Sim - 1)\n",
        "\n",
        "# Bootstrap settings\n",
        "N_BOOT = 20000\n",
        "SEED = 123\n",
        "\n",
        "\n",
        "# Provide y-limits as (ymin, ymax). Use None to auto-scale.\n",
        "YLIMS_SLOPE_RAW = (0.0, 3.5)     # for RAW slope plot\n",
        "YLIMS_DIFF_RAW  = (-1.75, 1.75)    # for RAW diff plot (Sim - Raw)\n",
        "\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 2) DATA (edit here or load CSV)\n",
        "# -----------------------------\n",
        "# Dictionary of datasets (decimal commas converted to Python floats with dots)\n",
        "# Use like:\n",
        "#   df = pd.DataFrame(DATASETS[\"Membranes\"], columns=cols).set_index(\"SampleId\")\n",
        "#   ... then run your script as before.\n",
        "\n",
        "DATASETS = {\n",
        "    \"Membranes\": [\n",
        "        [1, 1.806614033, 1.244329, 2.010325, 2.123197, 1.96224235, 1.056125304, 0.968543609, 0.951401791, 1.38136481],\n",
        "        [2, 1.780158856, 1.587453, 2.310405, 2.364202, 1.90970349, 1.032280176, 1.340440986, 1.34422002,  1.41036202],\n",
        "        [3, 2.794670776, 1.410881, 2.233726, 2.32189,  1.97548133, 1.207869547, 1.266338211, 1.264785327, 1.34391007],\n",
        "        [4, 2.387366378, 1.335237, 2.197305, 2.27554,  2.08748669, 1.093783597, 1.290943347, 1.332411236, 1.47142883],\n",
        "    ],\n",
        "    \"BC\": [\n",
        "        [1, 2.38091295,  1.507968645, 2.051961628, 2.077553513, 2.968303302, 1.122633657, 1.073217184, 1.067860149, 1.036504048],\n",
        "        [2, 2.253584921, 1.354850543, 1.991388888, 2.059436193, 2.750387085, 0.828711681, 1.103971433, 1.090953536, 1.066579403],\n",
        "        [3, 2.994040087, 1.493923585, 2.065334906, 2.100517469, 3.146904131, 1.171163186, 1.090762859, 1.080011643, 1.159330561],\n",
        "        [4, 2.908995564, 1.799609654, 2.170871239, 2.16878252,  2.868644959, 1.261496875, 1.11370219,  1.11226693,  1.050318264],\n",
        "    ],\n",
        "    \"Nuclei\": [\n",
        "        [1, 1.126918873, 1.314564988, 1.08521112,  0.988977551, 1.224655289, 1.335820202, 1.028610335, 0.965914229, 0.948928378],\n",
        "        [2, 1.14368939,  1.285778147, 1.016605085, 0.954045326, 1.070651379, 1.277675588, 0.93764407,  0.931364408, 0.918829984],\n",
        "        [3, 1.187160376, 1.320542097, 1.007440946, 0.964397061, 1.146398094, 1.317296317, 0.948804355, 0.950097115, 0.947777192],\n",
        "        [4, 1.152685269, 1.311786251, 1.022775749, 0.970830479, 1.11808701,  1.270055121, 0.970462586, 0.965509973, 0.959806381],\n",
        "    ],\n",
        "    \"Sinusoids\": [\n",
        "        [1, 1.595264445, 0.751947, 2.579401, 2.760093, 1.53925745, 0.875932074, 1.026441748, 0.965914229, 1.31619336],\n",
        "        [2, 1.598817933, 1.106758, 2.394629, 2.556625, 1.47430931, 1.046493878, 1.112603131, 0.931364408, 1.31359842],\n",
        "        [3, 1.634569875, 1.104118, 2.198634, 2.243178, 1.37310653, 1.118707708, 1.079191951, 0.950097115, 1.25130462],\n",
        "        [4, 1.65411978,  0.936226, 2.539545, 2.784977, 1.48416626, 0.968415401, 1.132933665, 0.965509973, 1.322955],\n",
        "    ],\n",
        "}\n",
        "\n",
        "cols = [\n",
        "    \"SampleId\", \"Raw\",\n",
        "    \"CSim_SNR1\", \"CSim_SNR5\", \"CSim_SNR15\", \"GANSim\",\n",
        "    \"CSimIsoRef_SNR1\", \"CSimIsoRef_SNR5\", \"CSimIsoRef_SNR15\", \"GAN_IsoRef\",\n",
        "]\n",
        "\n",
        "\n",
        "df = pd.DataFrame(DATASETS[element], columns=cols).set_index(\"SampleId\")\n",
        "\n",
        "# -----------------------------\n",
        "# 3) UTILITIES\n",
        "# -----------------------------\n",
        "def paired_cohens_dz(diff: np.ndarray) -> float:\n",
        "    \"\"\"Cohen's dz for paired designs using the difference vector.\"\"\"\n",
        "    diff = np.asarray(diff, dtype=float)\n",
        "    sd = diff.std(ddof=1)\n",
        "    return np.nan if sd == 0 else diff.mean() / sd\n",
        "\n",
        "\n",
        "def wilcoxon_effect_r(stat: wilcoxon) -> float:\n",
        "    \"\"\"\n",
        "    Approximate effect size r from Wilcoxon using normal approximation:\n",
        "      r = |Z| / sqrt(n)\n",
        "    SciPy doesn't return Z directly; we approximate via the p-value.\n",
        "    \"\"\"\n",
        "    # Two-sided p -> |Z|\n",
        "    p = stat.pvalue\n",
        "    n = stat.statistic  # not n; ignore\n",
        "    # Use inverse normal from p (approx). We'll use scipy if available; otherwise fallback.\n",
        "    try:\n",
        "        from scipy.stats import norm\n",
        "        z = abs(norm.isf(p / 2.0))\n",
        "    except Exception:\n",
        "        # crude fallback\n",
        "        z = abs(np.sqrt(2) * math.erfcinv(p))\n",
        "    # Determine n from input length captured outside; this function expects caller to pass n\n",
        "    return z  # caller will divide by sqrt(n)\n",
        "\n",
        "\n",
        "def bootstrap_ci(diff: np.ndarray, func=np.mean, n_boot: int = 20000, seed: int = 0, ci: float = 0.95):\n",
        "    \"\"\"Bootstrap CI for a statistic (default: mean) on paired differences.\"\"\"\n",
        "    rng = np.random.default_rng(seed)\n",
        "    diff = np.asarray(diff, dtype=float)\n",
        "    n = diff.size\n",
        "    idx = rng.integers(0, n, size=(n_boot, n))\n",
        "    samples = diff[idx]\n",
        "    stats = func(samples, axis=1)\n",
        "    alpha = (1.0 - ci) / 2.0\n",
        "    lo = np.quantile(stats, alpha)\n",
        "    hi = np.quantile(stats, 1 - alpha)\n",
        "    return float(lo), float(hi)\n",
        "\n",
        "\n",
        "def holm_correct(pvals: list[float]) -> np.ndarray:\n",
        "    \"\"\"Holm correction (stronger than Bonferroni, standard for post-hoc).\"\"\"\n",
        "    return multipletests(pvals, method=\"holm\")[1]\n",
        "\n",
        "\n",
        "def tost_equivalence_paired(x: np.ndarray, y: np.ndarray, low: float, high: float) -> dict:\n",
        "    \"\"\"\n",
        "    Robust wrapper for statsmodels.ttost_paired\n",
        "    Works across different statsmodels versions.\n",
        "    \"\"\"\n",
        "    from statsmodels.stats.weightstats import ttost_paired\n",
        "\n",
        "    x = np.asarray(x, float)\n",
        "    y = np.asarray(y, float)\n",
        "\n",
        "    res = ttost_paired(x, y, low, high)\n",
        "    print(res)\n",
        "    print(len(res))\n",
        "\n",
        "    # Newer versions return 3 objects\n",
        "    if len(res) == 3:\n",
        "        pvalue, res_low, res_high = res\n",
        "        t_low, p_low, df1 = res_low\n",
        "        t_high, p_high, df2 = res_high\n",
        "    else:\n",
        "        # Older versions return 4 values\n",
        "        t_low, p_low, t_high, p_high = res\n",
        "        pvalue = max(p_low, p_high)\n",
        "\n",
        "    return {\n",
        "        \"t_low\": float(t_low),\n",
        "        \"p_low\": float(p_low),\n",
        "        \"t_high\": float(t_high),\n",
        "        \"p_high\": float(p_high),\n",
        "        \"p_tost\": float(pvalue),\n",
        "    }\n",
        "\n",
        "\n",
        "def journal_style():\n",
        "    \"\"\"Matplotlib style for clean, journal-like plots + editable text in Illustrator.\"\"\"\n",
        "    plt.rcParams.update({\n",
        "        \"figure.dpi\": 150,\n",
        "        \"savefig.dpi\": 600,\n",
        "\n",
        "        # --- Fonts: use a common sans-serif that Illustrator handles well\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
        "\n",
        "        \"font.size\": 9,\n",
        "        \"axes.titlesize\": 10,\n",
        "        \"axes.labelsize\": 9,\n",
        "        \"xtick.labelsize\": 8,\n",
        "        \"ytick.labelsize\": 8,\n",
        "        \"legend.fontsize\": 8,\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"xtick.major.width\": 0.8,\n",
        "        \"ytick.major.width\": 0.8,\n",
        "\n",
        "        # --- Critical: keep text as text (not paths)\n",
        "        \"text.usetex\": False,\n",
        "        \"svg.fonttype\": \"none\",   # keep SVG text as text\n",
        "        \"pdf.fonttype\": 42,       # TrueType fonts in PDF (editable)\n",
        "        \"ps.fonttype\": 42,        # TrueType fonts in PS/SVG (better, but  still flaky)\n",
        "\n",
        "        # Avoid path simplification that can mess with text\n",
        "        \"path.simplify\": False,\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "def save_fig(fig, name: str):\n",
        "    fig.tight_layout()\n",
        "\n",
        "    pdf_path = OUT_DIR / f\"{OUT_PREFIX}_{name}.svg\"\n",
        "    png_path = OUT_DIR / f\"{OUT_PREFIX}_{name}.png\"\n",
        "\n",
        "    fig.savefig(pdf_path, bbox_inches=\"tight\")\n",
        "    fig.savefig(png_path, bbox_inches=\"tight\", dpi=600)\n",
        "\n",
        "# -----------------------------\n",
        "# 4) CORE ANALYSIS (modify signature + body)\n",
        "# -----------------------------\n",
        "def analyze_vs_target(\n",
        "    df: pd.DataFrame,\n",
        "    target: np.ndarray,\n",
        "    sim_cols: list[str],\n",
        "    eq_bounds: tuple[float, float],\n",
        "    title: str,\n",
        "    panel_prefix: str,\n",
        "    ylims_slope: tuple[float, float] | None = None,\n",
        "    ylims_diff: tuple[float, float] | None = None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Same analysis as before, but with explicit y-limits for:\n",
        "      - slope plot (ylims_slope)\n",
        "      - diff plot  (ylims_diff)\n",
        "    \"\"\"\n",
        "    journal_style()\n",
        "    n = df.shape[0]\n",
        "    target = np.asarray(target, float)\n",
        "\n",
        "    results = []\n",
        "    pvals = []\n",
        "\n",
        "    # Precompute diffs\n",
        "    diffs = {}\n",
        "    for col in sim_cols:\n",
        "        sim = df[col].to_numpy(float)\n",
        "        d = sim - target\n",
        "        diffs[col] = d\n",
        "\n",
        "        w = wilcoxon(d, alternative=\"two-sided\", zero_method=\"wilcox\", correction=False, mode=\"auto\")\n",
        "        pvals.append(w.pvalue)\n",
        "\n",
        "        dz = paired_cohens_dz(d)\n",
        "        try:\n",
        "            from scipy.stats import norm\n",
        "            z = abs(norm.isf(w.pvalue / 2.0))\n",
        "        except Exception:\n",
        "            z = np.nan\n",
        "        r = (z / math.sqrt(n)) if np.isfinite(z) else np.nan\n",
        "\n",
        "        mean_ci = bootstrap_ci(d, func=np.mean, n_boot=N_BOOT, seed=SEED)\n",
        "        med_ci  = bootstrap_ci(d, func=np.median, n_boot=N_BOOT, seed=SEED + 1)\n",
        "\n",
        "        tost = tost_equivalence_paired(df[col].to_numpy(float), target, eq_bounds[0], eq_bounds[1])\n",
        "\n",
        "        results.append({\n",
        "            \"simulation\": col,\n",
        "            \"n_animals\": n,\n",
        "            \"mean_diff\": float(np.mean(d)),\n",
        "            \"median_diff\": float(np.median(d)),\n",
        "            \"abs_mean_diff\": float(np.mean(np.abs(d))),\n",
        "            \"wilcoxon_stat\": float(w.statistic),\n",
        "            \"p_wilcoxon\": float(w.pvalue),\n",
        "            \"cohens_dz\": float(dz),\n",
        "            \"wilcoxon_r\": float(r),\n",
        "            \"boot95_mean_lo\": mean_ci[0],\n",
        "            \"boot95_mean_hi\": mean_ci[1],\n",
        "            \"boot95_median_lo\": med_ci[0],\n",
        "            \"boot95_median_hi\": med_ci[1],\n",
        "            \"tost_p\": tost[\"p_tost\"],\n",
        "            \"tost_p_low\": tost[\"p_low\"],\n",
        "            \"tost_p_high\": tost[\"p_high\"],\n",
        "            \"eq_low\": eq_bounds[0],\n",
        "            \"eq_high\": eq_bounds[1],\n",
        "        })\n",
        "\n",
        "    # Holm correction\n",
        "    p_adj = holm_correct(pvals)\n",
        "    for i in range(len(results)):\n",
        "        results[i][\"p_wilcoxon_holm\"] = float(p_adj[i])\n",
        "\n",
        "    res_df = pd.DataFrame(results).sort_values(\"abs_mean_diff\", ascending=True)\n",
        "\n",
        "    # -----------------------------\n",
        "    # FIGURE A: paired slope plot\n",
        "    # -----------------------------\n",
        "    figA, axA = plt.subplots(figsize=(5.0, 2.5))\n",
        "    x_positions = np.arange(len(sim_cols) + 1)\n",
        "    labels = [\"Target\"] + sim_cols\n",
        "    rng = np.random.default_rng(123)   # reproducible\n",
        "\n",
        "    jitter_width = 0.06                # adjust if needed\n",
        "    # jitter for each animal (same jitter used for all its points)\n",
        "    jitter = (rng.random(n) - 0.5) * 2 * jitter_width\n",
        "\n",
        "    axA.scatter(np.full(n, x_positions[0])+ jitter, target, s=25, zorder=3, marker=\"o\")\n",
        "\n",
        "    for i, col in enumerate(sim_cols, start=1):\n",
        "        sim = df[col].to_numpy(float)\n",
        "\n",
        "        axA.scatter(np.full(n, x_positions[i])+ jitter, sim, s=25, zorder=3, marker=\"o\")\n",
        "        for k in range(n):\n",
        "            axA.plot([x_positions[0] + jitter[k], x_positions[i] + jitter[k]], [target[k], sim[k]], linewidth=0.5, alpha=0.5)\n",
        "\n",
        "    #axA.set_xticks(x_positions)\n",
        "    #axA.set_xticklabels(labels, rotation=35, ha=\"right\")\n",
        "    axA.set_xticks(x_positions)\n",
        "    axA.set_xticklabels(list(\"abcde\")[:len(x_positions)])\n",
        "\n",
        "    axA.set_ylabel(\"Ax/Lat\")\n",
        "    #axA.set_title(f\"{title} — Paired slope plot\")\n",
        "\n",
        "    # Apply explicit slope y-limits (if provided)\n",
        "    axA.set_xlim((-0.5, 4.5))\n",
        "    if ylims_slope is not None:\n",
        "        axA.set_ylim(ylims_slope)\n",
        "\n",
        "    # Annotation position derived from the final y-limits\n",
        "    y0, y1 = axA.get_ylim()\n",
        "    y_annot = y1 - 0.02 * (y1 - y0)\n",
        "\n",
        "    for i, col in enumerate(sim_cols, start=1):\n",
        "        p = res_df.loc[res_df[\"simulation\"] == col, \"p_wilcoxon_holm\"].values[0]\n",
        "        axA.text(x_positions[i], y_annot, f\"p(Holm)={p:.3g}\", ha=\"center\", va=\"top\")\n",
        "\n",
        "    axA.set_yticklabels([])\n",
        "    save_fig(figA, f\"{panel_prefix}_A_slope\")\n",
        "    plt.close(figA)\n",
        "\n",
        "    # -----------------------------\n",
        "    # FIGURE B: difference plot (Sim - target)\n",
        "    # -----------------------------\n",
        "    figB, axB = plt.subplots(figsize=(5.0, 2.5))\n",
        "    axB.axhline(0, linewidth=1.0)\n",
        "    axB.axhspan(eq_bounds[0], eq_bounds[1], alpha=0.12)\n",
        "\n",
        "    rng = np.random.default_rng(SEED)\n",
        "\n",
        "    base_x = 2  # 'a' will be here (empty)\n",
        "    xpos = base_x + 1 + np.arange(len(sim_cols))   # 3,4,5,6\n",
        "    empty_x = base_x                                # 2\n",
        "\n",
        "    for i, col in enumerate(sim_cols):\n",
        "        d = diffs[col]\n",
        "        x = np.full(n, xpos[i])\n",
        "        jitter = (rng.random(n) - 0.5) * 0.12\n",
        "        axB.scatter(x + jitter, d, s=28, marker=\"o\", zorder=3)\n",
        "\n",
        "        lo, hi = bootstrap_ci(d, func=np.mean, n_boot=N_BOOT, seed=SEED + i + 10)\n",
        "        m = float(np.mean(d))\n",
        "        axB.plot([xpos[i] - 0.18, xpos[i] + 0.18], [m, m], linewidth=2.0)\n",
        "        axB.plot([xpos[i], xpos[i]], [lo, hi], linewidth=1.5)\n",
        "\n",
        "        p_tost = res_df.loc[res_df[\"simulation\"] == col, \"tost_p\"].values[0]\n",
        "        axB.text(xpos[i], hi, f\"TOST p={p_tost:.3g}\", ha=\"center\", va=\"bottom\", fontsize=5)\n",
        "\n",
        "    # ticks: a (empty), b,c,d,e for simulations\n",
        "    xticks = np.r_[empty_x, xpos]                 # [2,3,4,5,6]\n",
        "    xticklabels = list(\"abcde\")\n",
        "\n",
        "    axB.set_xticks(xticks)\n",
        "    axB.set_xticklabels(xticklabels)\n",
        "\n",
        "    axB.set_ylabel(\"Difference (Sim − Raw)\")\n",
        "    #axB.set_title(f\"{title} — Difference plot (mean ± boot95% CI)\")\n",
        "\n",
        "    # Give breathing space on both sides\n",
        "    #axB.set_xlim(base_x - 1, xpos[-1] + 1)\n",
        "    axB.set_xlim(base_x - 0.5, xpos[-1] + 0.5)\n",
        "    if ylims_diff is not None:\n",
        "        axB.set_ylim(ylims_diff)\n",
        "\n",
        "    axB.set_yticklabels([])\n",
        "    save_fig(figB, f\"{panel_prefix}_B_diff\")\n",
        "    plt.close(figB)\n",
        "\n",
        "    return res_df\n",
        "\n",
        "# -----------------------------\n",
        "# 5) RUN THE TWO VALIDATIONS YOU DESCRIBED\n",
        "# -----------------------------\n",
        "# A) \"Best reproduces Raw\" (Target = Raw)\n",
        "raw_target = df[\"Raw\"].to_numpy(float)\n",
        "sim_vs_raw = [\"CSim_SNR1\", \"CSim_SNR5\", \"CSim_SNR15\", \"GANSim\"]\n",
        "\n",
        "res_raw = analyze_vs_target(\n",
        "    df=df,\n",
        "    target=raw_target,\n",
        "    sim_cols=sim_vs_raw,\n",
        "    eq_bounds=EQ_BOUNDS_RAW,\n",
        "    title=\"Reproducing Raw\",\n",
        "    panel_prefix=\"RAW\",\n",
        "    ylims_slope=YLIMS_SLOPE_RAW,\n",
        "    ylims_diff=YLIMS_DIFF_RAW,\n",
        ")\n",
        "\n",
        "# B) \"IsoRef should match ideal value 1\" (Target = 1)\n",
        "iso_target = np.ones(df.shape[0], dtype=float)\n",
        "sim_vs_iso = [\"CSimIsoRef_SNR1\", \"CSimIsoRef_SNR5\", \"CSimIsoRef_SNR15\", \"GAN_IsoRef\"]\n",
        "\n",
        "res_iso = analyze_vs_target(\n",
        "    df=df,\n",
        "    target=iso_target,\n",
        "    sim_cols=sim_vs_iso,\n",
        "    eq_bounds=EQ_BOUNDS_ISO,\n",
        "    title=\"Recovering ideal isotropy (target=1)\",\n",
        "    panel_prefix=\"ISO\",\n",
        "    ylims_slope=YLIMS_SLOPE_RAW,\n",
        "    ylims_diff=YLIMS_DIFF_RAW,\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 6) SAVE SUMMARY TABLES\n",
        "# -----------------------------\n",
        "res_raw.to_csv(OUT_DIR /f\"{OUT_PREFIX}_summary_vs_raw.csv\", index=False)\n",
        "res_iso.to_csv(OUT_DIR /f\"{OUT_PREFIX}_summary_vs_iso.csv\", index=False)\n",
        "\n",
        "print(\"\\n=== Ranking (closest to target) — vs Raw ===\")\n",
        "print(res_raw[[\"simulation\", \"abs_mean_diff\", \"mean_diff\", \"boot95_mean_lo\", \"boot95_mean_hi\",\n",
        "               \"p_wilcoxon_holm\", \"tost_p\"]].to_string(index=False))\n",
        "\n",
        "print(\"\\n=== Ranking (closest to target) — vs ideal 1 ===\")\n",
        "print(res_iso[[\"simulation\", \"abs_mean_diff\", \"mean_diff\", \"boot95_mean_lo\", \"boot95_mean_hi\",\n",
        "               \"p_wilcoxon_holm\", \"tost_p\"]].to_string(index=False))\n",
        "\n",
        "print(\"\\nSaved figures:\")\n",
        "print(f\"  {OUT_PREFIX}_RAW_A_slope.eps/.png\")\n",
        "print(f\"  {OUT_PREFIX}_RAW_B_diff.eps/.png\")\n",
        "print(f\"  {OUT_PREFIX}_ISO_A_slope.eps/.png\")\n",
        "print(f\"  {OUT_PREFIX}_ISO_B_diff.eps/.png\")\n",
        "print(\"\\nSaved tables:\")\n",
        "print(f\"  {OUT_PREFIX}_summary_vs_raw.csv\")\n",
        "print(f\"  {OUT_PREFIX}_summary_vs_iso.csv\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7) NOTES (IMPORTANT FOR METHODS)\n",
        "# -----------------------------\n",
        "# - Wilcoxon tests: H0 median(Sim-Target)=0, Holm-corrected across sims in each family (vs Raw / vs 1).\n",
        "# - Bootstrap CI shown is for the MEAN difference; you also have median CI in the CSV.\n",
        "# - TOST is parametric (paired t-based) and tests equivalence within bounds EQ_BOUNDS_*.\n",
        "#   Choose EQ_BOUNDS_* based on scientific relevance (e.g., acceptable error margin in your descriptor)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import wilcoxon\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from statsmodels.stats.weightstats import ttost_paired\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 1) SETTINGS\n",
        "# =============================================================================\n",
        "OUT_PREFIX = \"radius_validation\"\n",
        "OUT_DIR = Path(\"/content/drive/MyDrive/Manuscripts/LivesIsotropicReconstruction/data/results/figure2d\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "EQ_BOUNDS = (-0.2, 0.2)  # equivalence bounds for mean difference\n",
        "\n",
        "N_BOOT = 20000\n",
        "SEED = 123\n",
        "\n",
        "YLIMS_SLOPE = (0.0, 1.75)\n",
        "YLIMS_DIFF  = (-0.25, 0.65)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 2) DATA (NEW ORDER)\n",
        "# =============================================================================\n",
        "# Min_raw | Avg_raw | Min_IdT | Avg_IdT\n",
        "data = [\n",
        "    [1.07833, 1.57522, 1.04385, 1.27235],\n",
        "    [1.09092, 1.54434, 1.02233, 1.08341],\n",
        "    [1.06669, 1.48987, 1.00339, 1.06661],\n",
        "    [1.06605, 1.54784, 1.03111, 1.29864],\n",
        "]\n",
        "\n",
        "cols = [\"Min_raw\", \"Avg_raw\", \"Min_IdT\", \"Avg_IdT\"]\n",
        "df = pd.DataFrame(data, columns=cols)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3) STATISTICAL UTILITIES\n",
        "# =============================================================================\n",
        "def paired_cohens_dz(diff):\n",
        "    diff = np.asarray(diff, dtype=float)\n",
        "    sd = diff.std(ddof=1)\n",
        "    return np.nan if sd == 0 else diff.mean() / sd\n",
        "\n",
        "\n",
        "def bootstrap_ci(diff, func=np.mean, n_boot=20000, seed=0, ci=0.95):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    diff = np.asarray(diff, dtype=float)\n",
        "    n = diff.size\n",
        "    idx = rng.integers(0, n, size=(n_boot, n))\n",
        "    stats = func(diff[idx], axis=1)\n",
        "    alpha = (1.0 - ci) / 2.0\n",
        "    return float(np.quantile(stats, alpha)), float(np.quantile(stats, 1 - alpha))\n",
        "\n",
        "\n",
        "def holm_correct(pvals):\n",
        "    return multipletests(pvals, method=\"holm\")[1]\n",
        "\n",
        "\n",
        "def tost_equivalence_paired(x, y, low, high):\n",
        "    res = ttost_paired(x, y, low, high)\n",
        "\n",
        "    if len(res) == 3:\n",
        "        pvalue, res_low, res_high = res\n",
        "        t_low, p_low, _ = res_low\n",
        "        t_high, p_high, _ = res_high\n",
        "    else:\n",
        "        t_low, p_low, t_high, p_high = res\n",
        "        pvalue = max(p_low, p_high)\n",
        "\n",
        "    return float(pvalue)\n",
        "\n",
        "\n",
        "def journal_style():\n",
        "    plt.rcParams.update({\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"svg.fonttype\": \"none\",\n",
        "        \"text.usetex\": False,\n",
        "        \"savefig.dpi\": 600,\n",
        "        \"font.size\": 9,\n",
        "    })\n",
        "\n",
        "\n",
        "def save_fig(fig, name):\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(OUT_DIR / f\"{OUT_PREFIX}_{name}.pdf\")\n",
        "    fig.savefig(OUT_DIR / f\"{OUT_PREFIX}_{name}.svg\")\n",
        "    fig.savefig(OUT_DIR / f\"{OUT_PREFIX}_{name}.png\", dpi=600)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 4) ANALYSIS\n",
        "# =============================================================================\n",
        "def analyze_vs_target(df, target_col, comp_cols,\n",
        "    ylims_slope: tuple[float, float] | None = None,\n",
        "    ylims_diff: tuple[float, float] | None = None,):\n",
        "\n",
        "    journal_style()\n",
        "\n",
        "    target = df[target_col].to_numpy(float)\n",
        "    n = len(target)\n",
        "\n",
        "    results = []\n",
        "    pvals = []\n",
        "    diffs = {}\n",
        "\n",
        "    for col in comp_cols:\n",
        "        x = df[col].to_numpy(float)\n",
        "        d = x - target\n",
        "        diffs[col] = d\n",
        "\n",
        "        w = wilcoxon(d)\n",
        "        pvals.append(w.pvalue)\n",
        "\n",
        "        mean_ci = bootstrap_ci(d, np.mean, N_BOOT, SEED)\n",
        "        tost_p = tost_equivalence_paired(x, target, *EQ_BOUNDS)\n",
        "\n",
        "        results.append({\n",
        "            \"comparison\": col,\n",
        "            \"mean_diff\": np.mean(d),\n",
        "            \"abs_mean_diff\": np.mean(np.abs(d)),\n",
        "            \"boot_lo\": mean_ci[0],\n",
        "            \"boot_hi\": mean_ci[1],\n",
        "            \"p_wilcoxon\": w.pvalue,\n",
        "            \"tost_p\": tost_p,\n",
        "        })\n",
        "\n",
        "    p_adj = holm_correct(pvals)\n",
        "    for i in range(len(results)):\n",
        "        results[i][\"p_wilcoxon_holm\"] = p_adj[i]\n",
        "\n",
        "    res_df = pd.DataFrame(results)\n",
        "\n",
        "    # ============================\n",
        "    # SLOPE PLOT\n",
        "    # ============================\n",
        "    figA, axA = plt.subplots(figsize=(6, 2.8))\n",
        "\n",
        "    x_positions = np.arange(len(comp_cols) + 1)\n",
        "    labels = [target_col] + comp_cols\n",
        "\n",
        "    jitter = (np.random.rand(n) - 0.5) * 0.08\n",
        "\n",
        "    axA.scatter(np.zeros(n)+jitter, target)\n",
        "\n",
        "    for i, col in enumerate(comp_cols, 1):\n",
        "        x = df[col].to_numpy(float)\n",
        "        axA.scatter(np.full(n, i)+jitter, x)\n",
        "\n",
        "        for k in range(n):\n",
        "            axA.plot([0+jitter[k], i+jitter[k]], [target[k], x[k]], alpha=0.5)\n",
        "\n",
        "        p = res_df.loc[res_df[\"comparison\"] == col, \"p_wilcoxon_holm\"].values[0]\n",
        "        #axA.text(i, max(target)*1.05, f\"p={p:.3g}\", ha=\"center\")\n",
        "\n",
        "    axA.set_xticks(x_positions)\n",
        "    axA.set_xticklabels(labels, rotation=35, ha=\"right\")\n",
        "    axA.set_ylabel(\"Radius\")\n",
        "\n",
        "    if ylims_slope is not None:\n",
        "        axA.set_ylim(ylims_slope)\n",
        "\n",
        "    save_fig(figA, \"A_slope\")\n",
        "    plt.close(figA)\n",
        "\n",
        "    # ============================\n",
        "    # DIFFERENCE PLOT\n",
        "    # ============================\n",
        "    figB, axB = plt.subplots(figsize=(6, 3))\n",
        "\n",
        "    axB.axhline(0)\n",
        "    axB.axhspan(*EQ_BOUNDS, alpha=0.15)\n",
        "\n",
        "    for i, col in enumerate(comp_cols):\n",
        "        d = diffs[col]\n",
        "        jitter = (np.random.rand(n) - 0.5) * 0.12\n",
        "        axB.scatter(np.full(n, i)+jitter, d)\n",
        "\n",
        "        m = np.mean(d)\n",
        "        lo, hi = bootstrap_ci(d, np.mean, N_BOOT, SEED+i)\n",
        "        axB.plot([i-0.2, i+0.2], [m, m], linewidth=2)\n",
        "        axB.plot([i, i], [lo, hi])\n",
        "\n",
        "        p_tost = res_df.loc[res_df[\"comparison\"] == col, \"tost_p\"].values[0]\n",
        "        axB.text(i, hi, f\"TOST={p_tost:.3g}\", ha=\"center\")\n",
        "\n",
        "    axB.set_xticks(np.arange(len(comp_cols)))\n",
        "    axB.set_xticklabels(comp_cols, rotation=35, ha=\"right\")\n",
        "    axB.set_ylabel(\"Difference (Comp − Min_raw)\")\n",
        "    if ylims_diff is not None:\n",
        "        axB.set_ylim(ylims_diff)\n",
        "\n",
        "    save_fig(figB, \"B_diff\")\n",
        "    plt.close(figB)\n",
        "\n",
        "    return res_df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 5) RUN\n",
        "# =============================================================================\n",
        "res = analyze_vs_target(\n",
        "    df,\n",
        "    target_col=\"Min_raw\",\n",
        "    comp_cols=[\"Avg_raw\", \"Min_IdT\", \"Avg_IdT\"],\n",
        "    ylims_slope=YLIMS_SLOPE,\n",
        "    ylims_diff=YLIMS_DIFF\n",
        ")\n",
        "\n",
        "print(res)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDLYI48phUr5",
        "outputId": "b5367c44-2ada-4329-9169-c3ea67add9c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  comparison  mean_diff  abs_mean_diff   boot_lo   boot_hi  p_wilcoxon  \\\n",
            "0    Avg_raw   0.463820       0.463820  0.437833  0.489340       0.125   \n",
            "1    Min_IdT  -0.050327       0.050327 -0.065945 -0.034710       0.125   \n",
            "2    Avg_IdT   0.104755       0.108550 -0.003795  0.213305       0.625   \n",
            "\n",
            "     tost_p  p_wilcoxon_holm  \n",
            "0  0.999745            0.375  \n",
            "1  0.000243            0.375  \n",
            "2  0.114400            0.625  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Paired slope plot + difference plot + bootstrap CI\n",
        "+ Wilcoxon (paired, Holm if multiple) + Equivalence testing (TOST)\n",
        "\n",
        "Adapted for: Nuclei elongation (Raw vs IdT), n=4 pairs\n",
        "\n",
        "Outputs: PDF + SVG (editable text) + 600 dpi PNG\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy.stats import wilcoxon\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from statsmodels.stats.weightstats import ttost_paired\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 1) SETTINGS\n",
        "# =============================================================================\n",
        "OUT_PREFIX = \"nuclei_elongation\"\n",
        "OUT_DIR = Path(\"/content/drive/MyDrive/Manuscripts/LivesIsotropicReconstruction/data/results/figure2e\")\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Equivalence bounds for paired differences: (IdT - Raw)\n",
        "# IMPORTANT: choose based on what you consider \"practically equivalent\"\n",
        "EQ_BOUNDS = (-0.05, 0.05)\n",
        "\n",
        "N_BOOT = 20000\n",
        "SEED = 123\n",
        "\n",
        "# Optional y-limits (set None to auto)\n",
        "YLIMS_SLOPE = (0.0, 0.25)\n",
        "YLIMS_DIFF  = (-0.15, 0.15)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 2) DATA (Raw | IdT)\n",
        "# =============================================================================\n",
        "data = [\n",
        "    [0.185472, 0.0444513],\n",
        "    [0.151785, 0.0350925],\n",
        "    [0.200817, 0.0672715],\n",
        "    [0.176964, 0.0500642],\n",
        "]\n",
        "cols = [\"Raw\", \"IdT\"]\n",
        "df = pd.DataFrame(data, columns=cols)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 3) UTILITIES\n",
        "# =============================================================================\n",
        "def bootstrap_ci(diff, func=np.mean, n_boot=20000, seed=0, ci=0.95):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    diff = np.asarray(diff, dtype=float)\n",
        "    n = diff.size\n",
        "    idx = rng.integers(0, n, size=(n_boot, n))\n",
        "    stats = func(diff[idx], axis=1)\n",
        "    alpha = (1.0 - ci) / 2.0\n",
        "    return float(np.quantile(stats, alpha)), float(np.quantile(stats, 1 - alpha))\n",
        "\n",
        "\n",
        "def holm_correct(pvals):\n",
        "    return multipletests(pvals, method=\"holm\")[1]\n",
        "\n",
        "\n",
        "def tost_equivalence_paired(x, y, low, high):\n",
        "    \"\"\"\n",
        "    Returns the overall TOST p-value (the max of the two one-sided p-values)\n",
        "    Compatible with different statsmodels versions.\n",
        "    \"\"\"\n",
        "    res = ttost_paired(np.asarray(x, float), np.asarray(y, float), low, high)\n",
        "\n",
        "    if len(res) == 3:\n",
        "        pvalue, res_low, res_high = res\n",
        "        # res_low/res_high are tuples: (t, p, df)\n",
        "        # We return pvalue directly (already combined)\n",
        "        return float(pvalue)\n",
        "    else:\n",
        "        t_low, p_low, t_high, p_high = res\n",
        "        return float(max(p_low, p_high))\n",
        "\n",
        "\n",
        "def journal_style():\n",
        "    plt.rcParams.update({\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
        "        \"pdf.fonttype\": 42,      # editable text in PDF\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"svg.fonttype\": \"none\",  # keep text as text in SVG\n",
        "        \"text.usetex\": False,\n",
        "        \"savefig.dpi\": 600,\n",
        "        \"font.size\": 9,\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"xtick.major.width\": 0.8,\n",
        "        \"ytick.major.width\": 0.8,\n",
        "    })\n",
        "\n",
        "\n",
        "def save_fig(fig, name):\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(OUT_DIR / f\"{OUT_PREFIX}_{name}.pdf\", bbox_inches=\"tight\")\n",
        "    fig.savefig(OUT_DIR / f\"{OUT_PREFIX}_{name}.svg\", bbox_inches=\"tight\")\n",
        "    fig.savefig(OUT_DIR / f\"{OUT_PREFIX}_{name}.png\", bbox_inches=\"tight\", dpi=600)\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 4) ANALYSIS (Raw is target, compare IdT)\n",
        "# =============================================================================\n",
        "def analyze_vs_target(\n",
        "    df: pd.DataFrame,\n",
        "    target_col: str,\n",
        "    comp_cols: list[str],\n",
        "    ylims_slope: tuple[float, float] | None = None,\n",
        "    ylims_diff: tuple[float, float] | None = None,\n",
        "):\n",
        "    journal_style()\n",
        "\n",
        "    target = df[target_col].to_numpy(float)\n",
        "    n = len(target)\n",
        "\n",
        "    results = []\n",
        "    pvals = []\n",
        "    diffs = {}\n",
        "\n",
        "    for col in comp_cols:\n",
        "        x = df[col].to_numpy(float)\n",
        "        d = x - target  # (Comp - Target)\n",
        "        diffs[col] = d\n",
        "\n",
        "        w = wilcoxon(d)  # two-sided by default\n",
        "        pvals.append(w.pvalue)\n",
        "\n",
        "        mean_ci = bootstrap_ci(d, np.mean, N_BOOT, SEED)\n",
        "        tost_p = tost_equivalence_paired(x, target, *EQ_BOUNDS)\n",
        "\n",
        "        results.append({\n",
        "            \"comparison\": col,\n",
        "            \"mean_diff\": float(np.mean(d)),\n",
        "            \"abs_mean_diff\": float(np.mean(np.abs(d))),\n",
        "            \"boot_lo\": mean_ci[0],\n",
        "            \"boot_hi\": mean_ci[1],\n",
        "            \"p_wilcoxon\": float(w.pvalue),\n",
        "            \"tost_p\": float(tost_p),\n",
        "            \"eq_low\": EQ_BOUNDS[0],\n",
        "            \"eq_high\": EQ_BOUNDS[1],\n",
        "        })\n",
        "\n",
        "    # Holm correction (here it is trivial because we compare only 1 column,\n",
        "    # but kept for consistency if you add more comparisons later)\n",
        "    p_adj = holm_correct(pvals)\n",
        "    for i in range(len(results)):\n",
        "        results[i][\"p_wilcoxon_holm\"] = float(p_adj[i])\n",
        "\n",
        "    res_df = pd.DataFrame(results)\n",
        "\n",
        "    # ============================\n",
        "    # SLOPE PLOT (paired)\n",
        "    # ============================\n",
        "    figA, axA = plt.subplots(figsize=(4.6, 2.8))\n",
        "    labels = [target_col] + comp_cols\n",
        "    x_positions = np.arange(len(labels))\n",
        "\n",
        "    rng = np.random.default_rng(SEED)\n",
        "    jitter = (rng.random(n) - 0.5) * 0.08\n",
        "\n",
        "    # target points\n",
        "    axA.scatter(np.full(n, x_positions[0]) + jitter, target, s=28, zorder=3)\n",
        "\n",
        "    # comparisons\n",
        "    for i, col in enumerate(comp_cols, start=1):\n",
        "        x = df[col].to_numpy(float)\n",
        "        axA.scatter(np.full(n, x_positions[i]) + jitter, x, s=28, zorder=3)\n",
        "\n",
        "        # connect paired points\n",
        "        for k in range(n):\n",
        "            axA.plot([x_positions[0] + jitter[k], x_positions[i] + jitter[k]],\n",
        "                     [target[k], x[k]], alpha=0.5, linewidth=0.8)\n",
        "\n",
        "        # annotate corrected p\n",
        "        p = res_df.loc[res_df[\"comparison\"] == col, \"p_wilcoxon_holm\"].values[0]\n",
        "        # place annotation near top of axis\n",
        "        y0, y1 = axA.get_ylim()\n",
        "        axA.text(x_positions[i], y1, f\"p(Holm)={p:.3g}\", ha=\"center\", va=\"top\")\n",
        "\n",
        "    axA.set_xticks(x_positions)\n",
        "    axA.set_xticklabels(labels, rotation=0)\n",
        "    axA.set_ylabel(\"Nuclei elongation\")\n",
        "    axA.set_title(\"Paired slope plot\")\n",
        "\n",
        "    if ylims_slope is not None:\n",
        "        axA.set_ylim(ylims_slope)\n",
        "\n",
        "    save_fig(figA, \"A_slope\")\n",
        "    plt.close(figA)\n",
        "\n",
        "    # ============================\n",
        "    # DIFFERENCE PLOT (IdT - Raw)\n",
        "    # ============================\n",
        "    figB, axB = plt.subplots(figsize=(4.6, 3.0))\n",
        "\n",
        "    axB.axhline(0, linewidth=1.0)\n",
        "    axB.axhspan(*EQ_BOUNDS, alpha=0.15)\n",
        "\n",
        "    for i, col in enumerate(comp_cols):\n",
        "        d = diffs[col]\n",
        "        rng = np.random.default_rng(SEED + 100 + i)\n",
        "        jitter = (rng.random(n) - 0.5) * 0.12\n",
        "\n",
        "        axB.scatter(np.full(n, i) + jitter, d, s=28, zorder=3)\n",
        "\n",
        "        m = float(np.mean(d))\n",
        "        lo, hi = bootstrap_ci(d, np.mean, N_BOOT, SEED + i)\n",
        "        axB.plot([i - 0.2, i + 0.2], [m, m], linewidth=2.0)\n",
        "        axB.plot([i, i], [lo, hi], linewidth=1.2)\n",
        "\n",
        "        p_tost = res_df.loc[res_df[\"comparison\"] == col, \"tost_p\"].values[0]\n",
        "        axB.text(i, hi, f\"TOST p={p_tost:.3g}\", ha=\"center\", va=\"bottom\")\n",
        "\n",
        "    axB.set_xticks(np.arange(len(comp_cols)))\n",
        "    axB.set_xticklabels(comp_cols)\n",
        "    axB.set_ylabel(\"Difference (IdT − Raw)\")\n",
        "    axB.set_title(\"Difference plot (mean ± boot95% CI)\")\n",
        "\n",
        "    if ylims_diff is not None:\n",
        "        axB.set_ylim(ylims_diff)\n",
        "\n",
        "    save_fig(figB, \"B_diff\")\n",
        "    plt.close(figB)\n",
        "\n",
        "    return res_df\n",
        "\n",
        "\n",
        "# =============================================================================\n",
        "# 5) RUN\n",
        "# =============================================================================\n",
        "res = analyze_vs_target(\n",
        "    df=df,\n",
        "    target_col=\"Raw\",\n",
        "    comp_cols=[\"IdT\"],\n",
        "    ylims_slope=YLIMS_SLOPE,\n",
        "    ylims_diff=YLIMS_DIFF,\n",
        ")\n",
        "\n",
        "print(res)\n",
        "\n",
        "print(\"\\nSaved figures:\")\n",
        "print(f\"  {OUT_PREFIX}_A_slope.pdf/.svg/.png\")\n",
        "print(f\"  {OUT_PREFIX}_B_diff.pdf/.svg/.png\")\n",
        "print(\"\\nSaved table columns:\")\n",
        "print(list(res.columns))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxh5iD8TnYEx",
        "outputId": "29f41aed-e15e-4140-9a0b-9cccf1586b66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  comparison  mean_diff  abs_mean_diff  boot_lo   boot_hi  p_wilcoxon  \\\n",
            "0        IdT   -0.12954        0.12954 -0.13749 -0.120906       0.125   \n",
            "\n",
            "     tost_p  eq_low  eq_high  p_wilcoxon_holm  \n",
            "0  0.999703   -0.05     0.05            0.125  \n",
            "\n",
            "Saved figures:\n",
            "  nuclei_elongation_A_slope.pdf/.svg/.png\n",
            "  nuclei_elongation_B_diff.pdf/.svg/.png\n",
            "\n",
            "Saved table columns:\n",
            "['comparison', 'mean_diff', 'abs_mean_diff', 'boot_lo', 'boot_hi', 'p_wilcoxon', 'tost_p', 'eq_low', 'eq_high', 'p_wilcoxon_holm']\n"
          ]
        }
      ]
    }
  ]
}