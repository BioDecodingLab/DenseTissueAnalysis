{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b48be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmorales/miniconda3/envs/selfnet/lib/python3.9/site-packages/pydantic/_migration.py:281: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from Supporting_functions import *\n",
    "from WBNS import WBNS_image\n",
    "import RedLionfishDeconv as rl\n",
    "\n",
    "import scipy.ndimage as ndi\n",
    "from aicsimageio.readers import CziReader\n",
    "from aicsimageio.writers import OmeTiffWriter\n",
    "import re\n",
    "\n",
    "from skimage import measure  \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c61d3cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "\n",
    "\n",
    "\n",
    "## Tiff source folders\n",
    "\n",
    "# Source paths for the tiff images if extractImagesFromCzi== True, the folders will be created\n",
    "srcpath = r'/run/user/1000/gvfs/smb-share:server=134.34.176.179,share=pmtest_fast/Daniel/SqtsfGFP_dataforHernan/croppedfortraining/'\n",
    "dirOut    = r'/run/user/1000/gvfs/smb-share:server=134.34.176.179,share=pmtest_fast/Daniel/SqtsfGFP_dataforHernan/croppedfortraining/Models/SqtsfGFP_test/'\n",
    "\n",
    "dirSource = srcpath + 'SqtsfGFP_allData/'  # this folder contain the tiffs\n",
    "\n",
    "\n",
    "## Generate image planes for training data \n",
    "dirTarget = dirSource\n",
    "\n",
    "## Process Target image \n",
    "processTargetImages = True\n",
    "\n",
    "# BG subtraction: not necessary\n",
    "resolution_px = 0 # FWHM of the PSF : 2 to 5 (~ radius of the structure , > 1)\n",
    "resolution_pz = 0\n",
    "noise_lvl = 2\n",
    "\n",
    "# deconvolution: not necessary\n",
    "psf_path = r'/run/user/1000/gvfs/smb-share:server=134.34.176.179,share=pmtest_fast/Daniel/SqtsfGFP_dataforHernan/Averaged_transformed_PSF_488.tif'\n",
    "padding = 32\n",
    "Niter = 0 # No pre-2D deconvolution\n",
    "\n",
    "# post processing\n",
    "sigmaLoG = 0.0\n",
    "sigmaLoGAddScale = 0.0\n",
    "sigma = 0.8\n",
    "\n",
    "# image normalization : Better no change\n",
    "thres_scale_target = 2.0 # threhold for simple mask for normalization\n",
    "percentiles_target = (10, 99.9999)\n",
    "min_v_target = 0\n",
    "max_v_target = 65535\n",
    "# save processed images\n",
    "dirProcTarget = srcpath + 'SqtsfGFP_allData_processed/' \n",
    "\n",
    "## Process Source image\n",
    "# image normalization\n",
    "processSourceImages = True\n",
    "thres_scale_source = 1.5  # threhold for simple mask for normalization\n",
    "percentiles_source = (10, 99.9999)\n",
    "min_v_source = 0\n",
    "max_v_source = 65535\n",
    "\n",
    "\n",
    "\n",
    "## Parameters for the patch selection\n",
    "patch_size = 64\n",
    "stride = 64\n",
    "signal_intensity_threshold = 10000  #parameter for selecting image patches containing signals\n",
    "add_flipped_pathes = True\n",
    "\n",
    "xy_interval=2\n",
    "xz_interval=2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab8f1bd",
   "metadata": {},
   "source": [
    "# Generate image planes for training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69713898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder: '/run/user/1000/gvfs/smb-share:server=134.34.176.179,share=pmtest_fast/Daniel/SqtsfGFP_dataforHernan/croppedfortraining/Models/SqtsfGFP_test/' already exists\n",
      "folder: '/run/user/1000/gvfs/smb-share:server=134.34.176.179,share=pmtest_fast/Daniel/SqtsfGFP_dataforHernan/croppedfortraining/Models/SqtsfGFP_test/raw_data/' already exists\n",
      "folder: '/run/user/1000/gvfs/smb-share:server=134.34.176.179,share=pmtest_fast/Daniel/SqtsfGFP_dataforHernan/croppedfortraining/Models/SqtsfGFP_test/raw_data/xy/' already exists\n",
      "folder: '/run/user/1000/gvfs/smb-share:server=134.34.176.179,share=pmtest_fast/Daniel/SqtsfGFP_dataforHernan/croppedfortraining/Models/SqtsfGFP_test/raw_data/xy_lr/' already exists\n",
      "folder: '/run/user/1000/gvfs/smb-share:server=134.34.176.179,share=pmtest_fast/Daniel/SqtsfGFP_dataforHernan/croppedfortraining/Models/SqtsfGFP_test/raw_data/xz/' already exists\n"
     ]
    }
   ],
   "source": [
    "## Create folders to export data\n",
    "outDir = dirOut+\"raw_data/\"\n",
    "xy_data = outDir+\"xy/\"\n",
    "xy_lr_data = outDir+\"xy_lr/\"\n",
    "xz_data = outDir+\"xz/\"\n",
    "   \n",
    "createFolder(dirOut)\n",
    "createFolder(outDir)\n",
    "createFolder(xy_data)\n",
    "createFolder(xy_lr_data)\n",
    "createFolder(xz_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967610ca",
   "metadata": {},
   "source": [
    "## Generate image planes for target and intermediate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c21cbd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Processing image : 18degr_singleTrack__2023_12_18__15_49_26_471(190)crop.tif\n",
      "     -image dimension from : (26, 321, 399) to (84, 321, 399)\n",
      "     -z-space from : 1.8695295485696815 to 0.5786639078906157\n",
      "     -threshold_value: 434.0\n",
      "Intensity Norm  from (0 , 778) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:02,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 2.8695 seconds, image 18degr_singleTrack__2023_12_18__15_49_26_471(190)crop.tif, 84 images exported \n",
      "** Processing image : 18degr_singleTrack__2023_12_18__15_49_26_471(200)crop.tif\n",
      "     -image dimension from : (51, 423, 420) to (165, 423, 420)\n",
      "     -z-space from : 1.8695295485696815 to 0.5778545877397196\n",
      "     -threshold_value: 424.0\n",
      "Intensity Norm  from (0 , 918) to  (0, 65534)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:09,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 6.6275 seconds, image 18degr_singleTrack__2023_12_18__15_49_26_471(200)crop.tif, 249 images exported \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all tif images in the target folder, process and export them\n",
    "image_names = sorted([f for f in os.listdir(dirTarget) if f.endswith('.tif')])\n",
    "\n",
    "if processTargetImages == True:\n",
    "    #Creat output folder\n",
    "    createFolder(dirProcTarget)\n",
    "    # Open PSF and Prepare PSF\n",
    "    psf = tifffile.imread(psf_path)\n",
    "    psf_f = psf.astype(np.float32)\n",
    "    psf_norm = psf_f/psf_f.sum()\n",
    "\n",
    "    \n",
    "count = 1\n",
    "for i, image_name in tqdm(enumerate(image_names)):\n",
    "\n",
    "    start_time = time.time()  # Record the start time \n",
    "    print(f\"** Processing image : {image_name}\")\n",
    "    \n",
    "    # Open image and get metadata\n",
    "    img_path = os.path.join(dirTarget, image_name)   \n",
    "    img = tifffile.imread(img_path)\n",
    "    img_shape = img.shape\n",
    "    [physical_pixel_sizeX,physical_pixel_sizeY,physical_pixel_sizeZ] = read_tiff_voxel_size(img_path)    \n",
    "    scale = physical_pixel_sizeX / physical_pixel_sizeZ\n",
    "    \n",
    "\n",
    "    \n",
    "    if processTargetImages == True:\n",
    "        # Make image isotropic\n",
    "        if abs(1.0-scale) > 1e-4: \n",
    "            img = reslice(img,'xy',physical_pixel_sizeX,physical_pixel_sizeZ)\n",
    "        img = img.astype(np.float32)\n",
    "        new_img_shape = img.shape   \n",
    "        new_physical_pixel_sizeZ = img_shape[0] * physical_pixel_sizeZ / new_img_shape[0]\n",
    "        print(f\"     -image dimension from : {img_shape} to {new_img_shape}\")\n",
    "        print(f\"     -z-space from : {physical_pixel_sizeZ} to {new_physical_pixel_sizeZ}\")\n",
    "\n",
    "        # Get mask\n",
    "        mask = get_image_simple_mask(img, 0.0, 1.0, thres_scale_target)  \n",
    "        mask =  mask.astype(np.int16)\n",
    "    \n",
    "        # Deconvolution\n",
    "        if Niter > 0: \n",
    "            # Padding image\n",
    "            img = np.pad(img, padding, mode='reflect')\n",
    "            imgSizeGB = img.nbytes / (1024 ** 3)\n",
    "            print('     -size(GB) : ', imgSizeGB)\n",
    "            # GPU deconvolution\n",
    "            res_gpu = rl.doRLDeconvolutionFromNpArrays(img, psf, niter=Niter,resAsUint8=False)\n",
    "            # Removing padding\n",
    "            img = res_gpu[padding:-padding, padding:-padding, padding:-padding]\n",
    "\n",
    "        # Remove noise and BG\n",
    "        if resolution_px > 0:\n",
    "            img = WBNS_image(img, resolution_px, noise_lvl)\n",
    "            if resolution_pz > 0:\n",
    "                img_xz=np.transpose(img,[1,0,2])\n",
    "                img_xz = WBNS_image(img_xz, resolution_pz, 0)\n",
    "                img = np.transpose(img_xz,[1,0,2])\n",
    "        # LoG filter\n",
    "        if sigmaLoG > 0 :\n",
    "            imgBorders = ndi.gaussian_laplace(img, sigmaLoG)\n",
    "            imgBorders *= -1.0\n",
    "            #imgBorders[imgBorders < 0] = 0\n",
    "            imgBorders *= sigmaLoGAddScale\n",
    "            img += imgBorders\n",
    "        \n",
    "        # Smooth\n",
    "        if sigma > 0:\n",
    "            img = ndi.gaussian_filter(img, sigma)\n",
    "        \n",
    "        # Image Normalization\n",
    "        if percentiles_target[0] > 0 or percentiles_target[1] < 100:\n",
    "            low_thres, high_thres0 = getNormalizationThresholds(img, percentiles_target) # low thres in whole image\n",
    "            low_thres0, high_thres = getNormalizationThresholds(img * mask, percentiles_target) # high thres in FG\n",
    "            img = remove_outliers_image(img, low_thres, high_thres)\n",
    "\n",
    "        img = image_scaling(img, min_v_target, max_v_target, True)\n",
    "        img = img.astype(np.uint16)\n",
    "        \n",
    "        # Save processed image\n",
    "        img_out_name = os.path.join(dirProcTarget, image_name)            \n",
    "        tifffile.imwrite(      \n",
    "            img_out_name,\n",
    "            img,\n",
    "            imagej=True, \n",
    "            resolution=(1.0/physical_pixel_sizeX, 1.0/physical_pixel_sizeY), \n",
    "            metadata={'spacing': new_physical_pixel_sizeZ, 'unit': 'um', 'axes': 'ZYX'})\n",
    "        \n",
    "    # Generate intermediate images down sample and then upsample\n",
    "    img_lr = np.zeros_like(img)\n",
    "    z,y,x = img.shape    \n",
    "    new_y = round(y * scale)\n",
    "    new_x = round(x * scale)\n",
    "    \n",
    "    for i in range(z):\n",
    "        temp_img  = cv2.resize(img[i,:,:],(new_x,new_y),interpolation=cv2.INTER_CUBIC)\n",
    "        #img_lr[i,:,:] = cv2.resize(temp_img,(x,y),interpolation=cv2.INTER_CUBIC)  \n",
    "        img_lr[i,:,:] = cv2.resize(temp_img,(x,y),interpolation=cv2.INTER_LINEAR) \n",
    "            \n",
    "    # Export planes for target and intermediate images, each plane as a TIFF image \n",
    "    \n",
    "    for i in range(z):\n",
    "        outName_target = f\"{xy_data}{count}.tif\"\n",
    "        outName_interm = f\"{xy_lr_data}{count}.tif\"\n",
    "        tifffile.imwrite(outName_target, img[i,:,:])\n",
    "        tifffile.imwrite(outName_interm, img_lr[i,:,:])      \n",
    "        count += 1\n",
    "  \n",
    "    Elapsed_time = time.time() - start_time\n",
    "    print(f\"Elapsed Time: {Elapsed_time:.4f} seconds, image {image_name}, {count-1} images exported \") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048bbdd",
   "metadata": {},
   "source": [
    "## Generate image planes for source images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8efc585b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** Processing image : 18degr_singleTrack__2023_12_18__15_49_26_471(190)crop.tif\n",
      "     -threshold_value: 324.0\n",
      "Intensity Norm  from (0 , 1041) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [00:03,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 3.2606 seconds, image 18degr_singleTrack__2023_12_18__15_49_26_471(190)crop.tif, 321 images exported \n",
      "** Processing image : 18degr_singleTrack__2023_12_18__15_49_26_471(200)crop.tif\n",
      "     -threshold_value: 319.5\n",
      "Intensity Norm  from (0 , 1216) to  (0, 65535)  \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:08,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 5.2339 seconds, image 18degr_singleTrack__2023_12_18__15_49_26_471(200)crop.tif, 744 images exported \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all tif images in the dirSource folder, process and export them\n",
    "image_names = sorted([f for f in os.listdir(dirSource) if f.endswith('.tif')])\n",
    "\n",
    "count = 1\n",
    "for i, image_name in tqdm(enumerate(image_names)):\n",
    "\n",
    "    start_time = time.time()  # Record the start time \n",
    "    print(f\"** Processing image : {image_name}\")\n",
    "    \n",
    "    # Open image and get metadata\n",
    "    img_path = os.path.join(dirSource, image_name)   \n",
    "    img = tifffile.imread(img_path)\n",
    "    img_shape = img.shape\n",
    "    [physical_pixel_sizeX,physical_pixel_sizeY,physical_pixel_sizeZ] = read_tiff_voxel_size(img_path)    \n",
    "    scale = physical_pixel_sizeX / physical_pixel_sizeZ\n",
    " \n",
    "\n",
    "    if processSourceImages: \n",
    "        # Get mask\n",
    "        mask = get_image_simple_mask(img, 0.0, 1.0, thres_scale_source)  \n",
    "        mask =  mask.astype(np.int16)\n",
    "        # Image Normalization\n",
    "        if percentiles_source[0] > 0 or percentiles_source[1] < 100:\n",
    "            low_thres, high_thres0 = getNormalizationThresholds(img, percentiles_source) # low thres in whole image\n",
    "            low_thres0, high_thres = getNormalizationThresholds(img * mask, percentiles_source) # high thres in FG\n",
    "            img = remove_outliers_image(img, low_thres, high_thres)\n",
    "\n",
    "        img = image_scaling(img, min_v_source, max_v_source, True)\n",
    "        img = img.astype(np.uint16)\n",
    "\n",
    "    # reslice Image\n",
    "    img_xz = reslice(img,'xz',physical_pixel_sizeX,physical_pixel_sizeZ)\n",
    "    \n",
    "    z,y,x = img_xz.shape \n",
    "    \n",
    "    for i in range(z):\n",
    "        outName_target = f\"{xz_data}{count}.tif\"\n",
    "        tifffile.imwrite(outName_target, img_xz[i,:,:])\n",
    "        count += 1\n",
    "  \n",
    "    Elapsed_time = time.time() - start_time\n",
    "    print(f\"Elapsed Time: {Elapsed_time:.4f} seconds, image {image_name}, {count-1} images exported \")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fc30eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01dc63a6",
   "metadata": {},
   "source": [
    "# Generate training data from image planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c25ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder output \n",
    "train_data_path = os.path.join(dirOut, 'train_data/')\n",
    "createFolder(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c095ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 2189/2189 [00:38<00:00, 56.60it/s]\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████▍| 2362/2375 [00:16<00:00, 130.34it/s]<tifffile.TiffFile '4749.tif'> <asarray> failed to reshape (0,) to (), raised ValueError('cannot reshape array of size 0 into shape ()')\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 2375/2375 [00:16<00:00, 146.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize arrays\n",
    "\n",
    "xy = []\n",
    "xy_lr = []\n",
    "xz = []\n",
    "\n",
    "# Loop over lateral images\n",
    "file_list_xy = os.listdir(xy_data)\n",
    "for i in tqdm(range(0, len(file_list_xy), xy_interval)):\n",
    "    xy_img = tifffile.imread(xy_data + str(i + 1) + '.tif')\n",
    "    xy_lr_img = tifffile.imread(xy_lr_data + str(i + 1) + '.tif')\n",
    "    L0 = min(xy_img.shape[0], xy_lr_img.shape[0])\n",
    "    L1 = min(xy_img.shape[1], xy_lr_img.shape[1])\n",
    "    for m in range(0, L0 - patch_size + 1, stride):\n",
    "        for n in range(0, L1 - patch_size + 1, stride):\n",
    "            crop_xy    =    xy_img[m:m + patch_size, n:n + patch_size]\n",
    "            crop_xy_lr = xy_lr_img[m:m + patch_size, n:n + patch_size]\n",
    "            \n",
    "            if np.max(crop_xy) >= signal_intensity_threshold:\n",
    "                xy.append(crop_xy)\n",
    "                xy_lr.append(crop_xy_lr)\n",
    "                if add_flipped_pathes:\n",
    "                    xy.append(cv2.flip(crop_xy, 1))\n",
    "                    xy_lr.append(cv2.flip(crop_xy_lr, 1))                    \n",
    "\n",
    "# Loop over axial images   \n",
    "file_list_xz = os.listdir(xz_data)\n",
    "for i in tqdm(range(0, len(file_list_xz), xz_interval)):\n",
    "    xz_img = tifffile.imread(xz_data + str(i + 1) + '.tif')\n",
    "    for m in range(0, xz_img.shape[0] - patch_size + 1, stride):\n",
    "        for n in range(0, xz_img.shape[1] - patch_size + 1, stride):\n",
    "            crop_xz = xz_img[m:m + patch_size, n:n + patch_size]\n",
    "\n",
    "            if np.max(crop_xz) >= signal_intensity_threshold:\n",
    "                xz.append(crop_xz)\n",
    "                if add_flipped_pathes:\n",
    "                    xz.append(cv2.flip(crop_xz,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43b1347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9288\n",
      "9288\n",
      "3856\n"
     ]
    }
   ],
   "source": [
    "print(len(xy))\n",
    "print(len(xy_lr))\n",
    "print(len(xz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad39f7d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9288, 64, 64) (9288, 64, 64) (3856, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Convert to arays and save\n",
    "\n",
    "xy = np.array(xy, dtype=np.float32)\n",
    "xy_lr = np.array(xy_lr, dtype=np.float32)\n",
    "xz = np.array(xz, dtype=np.float32)\n",
    "print(xy.shape, xy_lr.shape, xz.shape)\n",
    "\n",
    "np.savez(os.path.join(train_data_path, 'train_data.npz'), xy=xy, xy_lr=xy_lr, xz=xz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcd22c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save tiff to double check\n",
    "\n",
    "import tifffile as tiff\n",
    "tiff.imwrite(os.path.join(train_data_path,'xy.tif'), xy)\n",
    "tiff.imwrite(os.path.join(train_data_path,'xy_lr.tif'), xy_lr)\n",
    "tiff.imwrite(os.path.join(train_data_path,'xz.tif'), xz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501428f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
